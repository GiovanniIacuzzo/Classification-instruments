# ğŸµ Multilabel Classification of Musical Instruments using Spectrograms

Questo progetto si occupa della classificazione automatica di strumenti musicali a partire da dati audio trasformati in immagini (spettrogrammi). Il problema Ã¨ affrontato come una **classificazione multilabel**, confrontando le prestazioni di una **CNN (modello di deep learning)** con modelli tradizionali di machine learning: **XGBoost** e **Random Forest**.

## ğŸ“ Struttura del Dataset

Il dataset Ã¨ stato **raccolto manualmente** e comprende **registrazioni audio di 5 strumenti musicali**:

- Chitarra
- Pianoforte
- Violino
- Viola
- Flauto

I file `.wav` sono stati convertiti in spettrogrammi grigi con la libreria `librosa`.

Ogni spettrogramma Ã¨ poi salvato come immagine `.png` e suddiviso in:

- `train` (70%)
- `val` (15%)
- `test` (15%)

Organizzati nella seguente struttura:

```bash
data/
â”œâ”€â”€ train/
â”‚   â””â”€â”€ <strumento>/immagini/*.png
â”œâ”€â”€ val/
â”‚   â””â”€â”€ <strumento>/immagini/*.png
â”œâ”€â”€ test/
â”‚   â””â”€â”€ <strumento>/immagini/*.png
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model_immagini.py
â”‚
â”œâ”€â”€ pre data/
â”‚   â”œâ”€â”€ audio.py
â”‚   â”œâ”€â”€ clone.ipynb
â”‚   â””â”€â”€ segmentaion.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ dataset_immagini.py
â”‚   â”œâ”€â”€ evaluate_immagini.py
â”‚   â”œâ”€â”€ train_immagini.py
â”‚   â””â”€â”€ test_immagini.py
â”‚
â”œâ”€â”€ main_immagini.ipynb
â”œâ”€â”€ main.ipynb
â”‚
â”œâ”€â”€ extract_features.ipynb
â”œâ”€â”€ ispezione.ipynb
â”‚
â”œâ”€â”€ requirement.txt
â”œâ”€â”€ environment.yml
â”‚
â””â”€â”€ Readme.md
```

## ğŸ”§ Preprocessing: Da Audio a Spettrogrammi

Il preprocessing converte i file `.wav` in spettrogrammi tramite:

```bash
librosa.feature.melspectrogram()
librosa.power_to_db()
```
I file risultanti vengono salvati come immagini monocromatiche.

## ğŸ§  Modelli Utilizzati

Nel nostro progetto di classificazione multilabel degli strumenti musicali a partire da immagini spettrogrammi, abbiamo adottato e confrontato tre approcci differenti per valutare lâ€™efficacia di modelli basati su deep learning rispetto a metodi tradizionali di machine learning.

### 1. Convolutional Neural Network (CNN)

Abbiamo sviluppato un modello CNN personalizzato utilizzando PyTorch. Il modello Ã¨ composto da tre blocchi convoluzionali con Batch Normalization, MaxPooling e Dropout per prevenire l'overfitting. La rete termina con due layer fully connected.

- **Input:** spettrogrammi in scala di grigi (1 x 224 x 224)  
- **Output:** probabilitÃ  per ciascuna delle 5 classi (strumenti)  
- **Funzione di perdita:** `CrossEntropyLoss`  
- **Ottimizzatore:** Adam con learning rate di 0.001  
- **Early Stopping:** monitorato sulla *validation accuracy* con `patience = 5`

Durante l'addestramento, salviamo il modello con la migliore accuracy sulla validation e generiamo:

- Curva di loss e accuracy per training e validation  
- Matrice di confusione finale  
- Classificazione dettagliata per classe

---

### 2. XGBoost (XGBClassifier)

Come approccio alternativo, abbiamo estratto feature statistiche dagli spettrogrammi (es. media, deviazione standard, skewness) e le abbiamo utilizzate per addestrare un classificatore `XGBClassifier`.

- **Modello:** Gradient Boosting (XGBoost)  
- **Vantaggi:** veloce da addestrare, interpretabilitÃ  delle feature  
- **Limiti:** richiede estrazione manuale delle caratteristiche e non sfrutta pienamente la struttura spaziale dellâ€™immagine

---

### 3. Random Forest

Abbiamo infine testato un classificatore Random Forest, anchâ€™esso basato su feature estratte manualmente dagli spettrogrammi. Ãˆ stato utilizzato come baseline classico:

- **Modello:** ensemble di alberi decisionali  
- **Punti di forza:** robustezza a overfitting e facilitÃ  di interpretazione  
- **Limiti:** prestazioni inferiori rispetto alla CNN

---

## ğŸ” Confronto

| Modello         | Feature Input            | Approccio        | Vantaggio Principale                         | Accuracy                     |
|-----------------|--------------------------|------------------|----------------------------------------------|------------------------------|
| **CNN**         | Immagini (spettrogrammi) | Deep Learning    | Apprendimento automatico dalle immagini      | ğŸ” Alta (da valutazione finale) |
| **XGBoost**     | Feature estratte         | Machine Learning | Ottima performance su feature numeriche      | Media                        |
| **Random Forest** | Feature estratte       | Machine Learning | Semplice e interpretabile                    | PiÃ¹ bassa                    |


## ğŸ›  Requisiti
```bash
torch
torchvision
matplotlib
seaborn
pandas
scikit-learn
librosa
```
Puoi installarli con:
```bash
pip install -r requirements.txt
```

## ğŸ“ Licenza
da inserire

